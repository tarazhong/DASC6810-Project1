import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier


diabetes = pd.read_csv("healthcare-dateset_diabetes.csv")
diabetes.head()


diabetes.isna().sum()


diabetes['Outcome'].value_counts() #data is balanced


diabetes.describe() #lots of variables with min 0


#calculate the proportion of zero values in each attribute
columns_to_check = ["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]
zero_ratios = (diabetes[columns_to_check] == 0).mean()
print(zero_ratios)


diabetes_mean = diabetes[columns_to_check].mean()
diabetes[columns_to_check]=diabetes[columns_to_check].replace(0, diabetes_mean)


#check for outliers
sns.boxplot(data=diabetes)
plt.xticks(rotation=90)  # Rotate x-axis labels for better readability
plt.title('Box Plot for Numerical Columns')
plt.show()


#remove outliers in insulin var
def remove_outliers(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]
    return df
    
diabetes = remove_outliers(diabetes,"Insulin")


#data visualization
variables = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 
             'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']
fig, axes = plt.subplots(4, 2, figsize=(14, 20))  
axes = axes.flatten()  

for i, var in enumerate(variables):
    sns.histplot(data=diabetes, x=var, hue='Outcome', kde=True, ax=axes[i])
    axes[i].set_title(f'{var} Distribution by Outcome')
    axes[i].set_xlabel(var)
    axes[i].set_ylabel('Count')

plt.tight_layout()
plt.show()


#correlation
plt.figure(figsize=(12,10))  
p=sns.heatmap(diabetes.corr(), annot=True,cmap ='RdYlGn')  


X = diabetes.drop("Outcome",axis=1)
y = diabetes["Outcome"]

scaler = StandardScaler()
X_scaled =  pd.DataFrame(scaler.fit_transform(X),columns=X.columns)

#split the data into training and test set
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=123)

X_scaled.head()


##logistic regression
logistic_regression = LogisticRegression()
logistic_regression.fit(X_train, y_train)
y_pred_log = logistic_regression.predict(X_test)
print(classification_report(y_test, y_pred_log))


#define the function for confusion matrix
def plot_confusion_matrix(y_test, y_prediction):
    cm = metrics.confusion_matrix(y_test, y_prediction)
    ax = plt.subplot()
    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')
    ax.set_xlabel('Prediced labels')
    ax.set_ylabel('True labels')
    ax.set_title('Confusion Matrix')
    ax.xaxis.set_ticklabels(['No Diabetes', 'Diabetes'])
    ax.yaxis.set_ticklabels(['No Diabetes', 'Diabetes']) 
    plt.show()


plot_confusion_matrix(y_test, y_pred_log)


#calculate the sensitivity and specificity
cm_log = confusion_matrix(y_test, y_pred_log)
TN, FP, FN, TP = cm_log.ravel()
sensitivity = TP / (TP + FN)  
specificity = TN / (TN + FP)  
print(f"Sensitivity: {sensitivity:.2f}") 
print(f"Specificity: {specificity:.2f}") #not bad


#Adjust class weights to handle imbalanced data
logistic_regression2 = LogisticRegression(class_weight="balanced")  #model assigns higher weights to stroke=1
logistic_regression2.fit(X_train, y_train)

y_pred_log2 = logistic_regression2.predict(X_test)
print(classification_report(y_test, y_pred_log2))

cm_log2 = confusion_matrix(y_test, y_pred_log2)
TN, FP, FN, TP = cm_log2.ravel()
sensitivity = TP / (TP + FN)   
specificity = TN / (TN + FP)  
print(f"Sensitivity: {sensitivity:.2f}") 
print(f"Specificity: {specificity:.2f}")


#use SMOTE to handle reduce class imbalance
from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=123)
X_train_balanced,y_train_balanced = smote.fit_resample(X_train, y_train)
logistic_regression3=LogisticRegression()
logistic_regression3.fit(X_train_balanced,y_train_balanced)
y_pred_log3 = logistic_regression3.predict(X_test)
print(classification_report(y_test,y_pred_log3))

cm_log3 = confusion_matrix(y_test, y_pred_log3)
TN, FP, FN, TP = cm_log3.ravel()
sensitivity = TP / (TP + FN)   
specificity = TN / (TN + FP)  
print(f"Sensitivity: {sensitivity:.2f}") 
print(f"Specificity: {specificity:.2f}")


##KNN
#use the elbow method to find the best k
k_values = range(1, 30, 2)  
error_rates = []  

# compute error rate for different k
for k in k_values:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)  
    y_pred = knn.predict(X_test)  
    error = 1 - accuracy_score(y_test, y_pred)  
    error_rates.append(error)

# plot k vs. error rate 
plt.figure(figsize=(8, 5))
plt.plot(k_values, error_rates, marker='o', linestyle='dashed', color='b')
plt.xlabel("Number of Neighbors (k)")
plt.ylabel("Error Rate")
plt.title("Elbow Method for Choosing k")
plt.xticks(k_values)  
plt.grid(True)

best_k = k_values[np.argmin(error_rates)]
print(f"Best k based on Elbow Method: {best_k}")

plt.show()


# use the optimal k for the model
knn = KNeighborsClassifier(n_neighbors=best_k)
knn.fit(X_train, y_train)  # Train the model on the full training set
y_pred_knn = knn.predict(X_test)

print(classification_report(y_test, y_pred_knn))

#display the confusion matrix
plot_confusion_matrix(y_test, y_pred_knn)

cm_knn = confusion_matrix(y_test, y_pred_knn)
TN, FP, FN, TP = cm_knn.ravel()
sensitivity = TP / (TP + FN)   
specificity = TN / (TN + FP)  
print(f"Sensitivity: {sensitivity:.2f}") 
print(f"Specificity: {specificity:.2f}")


from imblearn.over_sampling import SMOTE

#we will use smote to balance the data and decrease k to increase the sensitivity (class_weight doesn't apply to knn)
smote = SMOTE(sampling_strategy='auto', random_state=123)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

knn2 = KNeighborsClassifier(n_neighbors=3, weights="distance")
knn2.fit(X_train_resampled, y_train_resampled)
y_pred_knn2 = knn2.predict(X_test)

print(classification_report(y_test, y_pred_knn2))

cm_knn2 = confusion_matrix(y_test, y_pred_knn2)
TN, FP, FN, TP = cm_knn2.ravel()
sensitivity = TP / (TP + FN)   
specificity = TN / (TN + FP)  
print(f"Sensitivity: {sensitivity:.2f}") 
print(f"Specificity: {specificity:.2f}")


##neural network
#basic model
mlp_baseline = MLPClassifier(hidden_layer_sizes=(32,),  
                             activation='relu',       
                             solver='adam',           
                             max_iter=1000,           
                             random_state=123)

mlp_baseline.fit(X_train, y_train)
y_pred_nn_baseline = mlp_baseline.predict(X_test)

print(classification_report(y_test, y_pred_nn_baseline))
plot_confusion_matrix(y_test, y_pred_nn_baseline)

cm_nn_baseline = confusion_matrix(y_test, y_pred_nn_baseline)
TN, FP, FN, TP = cm_nn_baseline.ravel()
sensitivity = TP / (TP + FN)
specificity = TN / (TN + FP)
print(f"Sensitivity: {sensitivity:.2f}")
print(f"Specificity: {specificity:.2f}")


#adjustment
smote = SMOTE(sampling_strategy='auto', random_state=123)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

mlp_balanced = MLPClassifier(hidden_layer_sizes=(32,), max_iter=1000,random_state=123)
mlp_balanced.fit(X_train_resampled, y_train_resampled)


y_pred_nn_balanced = mlp_balanced.predict(X_test)
print(classification_report(y_test, y_pred_nn_balanced))

cm_nn_balanced = confusion_matrix(y_test, y_pred_nn_balanced)
TN, FP, FN, TP = cm_nn_balanced.ravel()
sensitivity = TP / (TP + FN)
specificity = TN / (TN + FP)
print(f"Sensitivity: {sensitivity:.2f}")
print(f"Specificity: {specificity:.2f}")
